{% extends base_layout %}
{% block title %}<title>{{app_name}} Â» Demos</title>{% endblock %}

{% block page_css %}
	<style>
	.hidden{
		display: none;
	}
	.wrapper {
	height: 100%;
	display: flex;
	flex-direction: column;
	}

	.main-controls {
	padding: 0.5rem 0;
	}

	canvas {
	display: block;
	margin-bottom: 0.5rem;
	}

	#buttons {
	display: flex;
	flex-direction: row;
	justify-content: space-between;
	}

	#buttons button {
	font-size: 1rem;
	padding: 1rem;
	width: calc(50% - 0.25rem);
	}

	button {
	font-size: 1rem;
	background: #0088cc;
	text-align: center;
	color: white;
	border: none;
	transition: all 0.2s;
	padding: 0.5rem;
	}

	button:hover, button:focus {
	box-shadow: inset 0px 0px 10px rgba(255, 255, 255, 1);
	background: #0ae;
	}

	button:active {
	box-shadow: inset 0px 0px 20px rgba(0,0,0,0.5);
	transform: translateY(2px);
	}


	/* Make the clips use as much space as possible, and
	* also show a scrollbar when there are too many clips to show
	* in the available space */
	.sound-clips {
	flex: 1;
	overflow: auto;
	}

	.clip {
	padding-bottom: 3rem;
	}

	audio {
	width: 100%;
	display: block;
	margin: 1rem auto 0.5rem;
	}

	.clip p {
	display: inline-block;
	font-size: 1rem;
	}

	.clip button {
	font-size: 1rem;
	float: right;
	}

	button.delete {
	background: #f00;
	padding: 0.5rem 0.75rem;
	font-size: 0.8rem;
	}

	button.process {
	background: rgb(2, 173, 39);
	padding: 0.5rem 0.75rem;
	font-size: 0.8rem;
	margin-right: 6px;
	}

	/* Checkbox hack to control information box display */

	label {
	font-size: 3rem;
	position: absolute;
	top: 2px;
	right: 3px;
	z-index: 5;
	cursor: pointer;
	}

	input[type=checkbox] {
	position: absolute;
	top: -100px;
	}
	
	/* Toggled State of information box */
	input[type=checkbox]:checked ~ aside {
	transform: translateX(0);
	}

	/* Cursor when clip name is clicked over */

	.clip p {
	cursor: pointer;
	}
	
	</style>
{% endblock %}

{% block breadcrums %}
<!--breadcrumbs start-->
<div id="breadcrumbs-wrapper" class=" grey lighten-3" style="  min-height: 70px;">
    <div class="container">
        <div class="row">
          <div class="col s12">
          <ol class="breadcrumb" style="font-size: 29px;">
                <li class="active">AI for Speech and Language</li>
            </ol></div>
        </div>
    </div>
</div>
<!--breadcrumbs end-->
{% endblock %}


{% block page_content %}
<div class="section">
    <div class="container">
        <h5 class="grey-text">Test pre-trained models for speech and language processing.</h5>
        <div class="container card" style="padding:50px;">
	    	<div class="col s10 offset-s1">
	    		<div class="row">
                    <div class="col s12" style="display:none">
						<div class="wrapper">						
							<section class="main-controls">
								<canvas class="visualizer" height="60px"></canvas>
								<div id="buttons">
									<button class="record">Record</button>
									<button class="stop">Stop</button>
								</div>
							</section>
						
							<section class="sound-clips">
								
						
							</section>
						
						</div>
					</div>
					<div class="col s12">
						<section class="sound-clips">
							<article class="clip">
								<audio controls>
									<source src="https://storage.googleapis.com/cloud-samples-tests/speech/brooklyn.flac"> Your browser does not support the audio element.
								</audio>
								<button class="process" onclick="sTT(1);">Analyze</button>

								<audio controls>
									<source src="https://storage.googleapis.com/mboilerplate.appspot.com/douglas.flac"> Your browser does not support the audio element.
								</audio>
								<button class="process" onclick="sTT(2);">Analyze</button>
							</article>
							<span id="confidence"></span>
						</section>
					</div>
                    <div class="input-field col s12">
                        <textarea id="nlp_input" name="nlp_input" class="materialize-textarea" length="500" style="height: 22px;" type="text" >
                        Google, headquartered in Mountain View, unveiled the new Android phone at the Consumer Electronic Show.  Sundar Pichai said in his keynote that users love their new Android phones.
                        </textarea>
                        <label for="nlp_input" class="active">Write here the text to parse using ML pre-trained models or use sample audios to analyze speech.</label>
                    </div>
                    <div class="row">
			        	<div class="input-field col s10 offset-s1 center">
			                <button class="waves-effect waves-light brand-color white-text btn-large right" id="submit_report_form">Analyze
			                    <i class="mdi-content-send right"></i>
			                </button>	                          
			            </div>
			        </div>
			        <div class="row" id="nlp_response"></div>
                </div>    
            </div>
	    </div>
    </div>
</div>
{% endblock %}


<!-- Remove floating button from home -->
{% block page_floatings %}
{% endblock %}



{% block page_scripts %}
	<!-- SPEECH SCRIPTS https://cloud.google.com/speech/reference/rest/v1/speech/recognize -->
	<script>
		/*
			// set up basic variables for app
			var record = document.querySelector('.record');
			var stop = document.querySelector('.stop');
			var soundClips = document.querySelector('.sound-clips');
			var canvas = document.querySelector('.visualizer');
			var mainSection = document.querySelector('.main-controls');
			// disable stop button while not recording
			stop.disabled = true;
			// visualiser setup - create web audio api context and canvas
			var audioCtx = new (window.AudioContext || webkitAudioContext)();
			var canvasCtx = canvas.getContext("2d");
			//main block for doing the audio recording
			if (navigator.mediaDevices.getUserMedia) {
				console.log('getUserMedia supported.');

				var constraints = { audio: true };
				var chunks = [];

				var onSuccess = function (stream) {
					var options = {
						audioBitsPerSecond : 16000
					};
					var mediaRecorder = new MediaRecorder(stream, options);

					visualize(stream);

					record.onclick = function () {
						mediaRecorder.start();
						console.log(mediaRecorder.state);
						console.log("recorder started");
						record.style.background = "red";

						stop.disabled = false;
						record.disabled = true;
					}

					stop.onclick = function () {
						mediaRecorder.stop();
						console.log(mediaRecorder.state);
						console.log("recorder stopped");
						record.style.background = "";
						record.style.color = "";
						//console.log('mR data: ', mediaRecorder.requestData());

						stop.disabled = true;
						record.disabled = false;
					}

					mediaRecorder.onstop = function (e) {
						console.log("data available after MediaRecorder.stop() called.");

						var clipContainer = document.createElement('article');
						var audio = document.createElement('audio');
						var deleteButton = document.createElement('button');
						var processButton = document.createElement('button');
						var blobstore = document.createElement('input');

						clipContainer.classList.add('clip');
						audio.setAttribute('controls', '');
						deleteButton.textContent = 'Delete';
						deleteButton.className = 'delete';
						processButton.textContent = 'Analyze';
						processButton.className = 'process';
						blobstore.setAttribute('type', 'text'); 
						blobstore.className = 'hidden';

						clipContainer.appendChild(audio);
						clipContainer.appendChild(deleteButton);
						clipContainer.appendChild(processButton);
						soundClips.appendChild(clipContainer);

						audio.controls = true;
						var blob = new Blob(chunks, { 'type': 'audio/ogg; codecs=opus' });
						var reader = new FileReader();
						reader.readAsDataURL(blob);
						reader.onloadend = function () {
							base64 = reader.result;
							base64 = base64.split(',')[1];
							blobstore.setAttribute('value', base64);
							clipContainer.appendChild(blobstore);
						}
						chunks = [];
						var audioURL = window.URL.createObjectURL(blob);
						audio.src = audioURL;
						console.log("recorder stopped");

						deleteButton.onclick = function (e) {
							evtTgt = e.target;
							evtTgt.parentNode.parentNode.removeChild(evtTgt.parentNode);
						}

						processButton.onclick = function (e) {
							evtTgt = e.target;
							processAudio(evtTgt.parentNode);
						}				

					}

					mediaRecorder.ondataavailable = function (e) {
						chunks.push(e.data);
					}
				}

				var onError = function (err) {
					console.log('The following error occured: ' + err);
				}

				navigator.mediaDevices.getUserMedia(constraints).then(onSuccess, onError);

			} else {
				console.log('getUserMedia not supported on your browser!');
			}
			
			function visualize(stream) {
				var source = audioCtx.createMediaStreamSource(stream);

				var analyser = audioCtx.createAnalyser();
				analyser.fftSize = 2048;
				var bufferLength = analyser.frequencyBinCount;
				var dataArray = new Uint8Array(bufferLength);

				source.connect(analyser);
				//analyser.connect(audioCtx.destination);

				draw()

				function draw() {
					WIDTH = canvas.width
					HEIGHT = canvas.height;

					requestAnimationFrame(draw);

					analyser.getByteTimeDomainData(dataArray);

					canvasCtx.fillStyle = 'rgb(200, 200, 200)';
					canvasCtx.fillRect(0, 0, WIDTH, HEIGHT);

					canvasCtx.lineWidth = 2;
					canvasCtx.strokeStyle = 'rgb(0, 0, 0)';

					canvasCtx.beginPath();

					var sliceWidth = WIDTH * 1.0 / bufferLength;
					var x = 0;


					for (var i = 0; i < bufferLength; i++) {

						var v = dataArray[i] / 128.0;
						var y = v * HEIGHT / 2;

						if (i === 0) {
							canvasCtx.moveTo(x, y);
						} else {
							canvasCtx.lineTo(x, y);
						}

						x += sliceWidth;
					}

					canvasCtx.lineTo(canvas.width, canvas.height / 2);
					canvasCtx.stroke();

				}
			}

			window.onresize = function () {
				canvas.width = mainSection.offsetWidth;
			}

			window.onresize();

			function processAudio(node){
				SpeechToText(node.getElementsByTagName("INPUT")[0].value);
			}
		*/
		function SpeechToText(data){
			if (data != '') {
				console.log('computing speech analysis...');
				Materialize.toast('<span class="toast-info">Please wait, computing speech analysis...</span>', 4500);
				$.ajax({
					url: "https://speech.googleapis.com/v1/speech:recognize?key={{google_speech_key}}",
					type: 'POST',
					contentType: "application/json",
					data: JSON.stringify({   // provision audio content or uri not both; either of them should be in the format specified in config
						"config": { //https://cloud.google.com/speech/reference/rest/v1/RecognitionConfig#AudioEncoding
							"encoding": "FLAC",
							"sampleRateHertz": 16000,
							"languageCode": "en-US"
							//"maxAlternatives": number,
							//"profanityFilter": boolean,
							/* "speechContexts": [
								{
									object(SpeechContext)
								}
							],*/
							//"enableWordTimeOffsets": boolean,
						},
						"audio": { //https://cloud.google.com/speech/reference/rest/v1/RecognitionAudio
							"content": data
							//"uri": "gs://cloud-samples-tests/speech/brooklyn.flac" // must be in the format gs://bucket_name/object_name; gs://cloud-samples-tests/speech/vr.flac
							
						}
					})
				}).done(function (response) {
					console.log('speech api response: ', response); //if response is empty check POST format and sample rate					
				});
			}
			else
				Materialize.toast('<span class="toast-warning">Please add some value to process.</span>', 4500);
		}

		function sTT(data){
			if (data == 1) {
				console.log('computing speech analysis...');
				Materialize.toast('<span class="toast-info">Please wait a second, computing speech analysis...</span>', 4500);
				$.ajax({
					url: "https://speech.googleapis.com/v1/speech:recognize?key={{google_speech_key}}",
					type: 'POST',
					contentType: "application/json",
					data: JSON.stringify({
						"config": { 
							"encoding": "FLAC",
							"sampleRateHertz": 16000,
							"languageCode": "en-US"
						},
						"audio": {
							"uri": "gs://cloud-samples-tests/speech/brooklyn.flac" 
						}
					})
				}).done(function (response) {
					console.log('speech api response: ', response);	
					document.getElementById('nlp_input').value = response.results[0].alternatives[0].transcript;
					$('#submit_report_form').click();
					$('#confidence').html('Confidence of recognized speech to text: ' + response.results[0].alternatives[0].confidence);
				});
			} else if (data == 2) {
				console.log('computing speech analysis...');
				Materialize.toast('<span class="toast-info">Please be patient, computing speech analysis...</span>', 4500);
				$.ajax({
					url: "https://speech.googleapis.com/v1/speech:recognize?key={{google_speech_key}}",
					type: 'POST',
					contentType: "application/json",
					data: JSON.stringify({
						"config": {
							"encoding": "FLAC",
							"sampleRateHertz": 44100,
							"languageCode": "en-US"
						},
						"audio": {
							"uri": "gs://mboilerplate.appspot.com/douglas.flac"

						}
					})
				}).done(function (response) {
					console.log('speech api response: ', response);
					document.getElementById('nlp_input').value = response.results[0].alternatives[0].transcript;
					$('#submit_report_form').click();	
					$('#confidence').html('Confidence of recognized speech to text: ' + response.results[0].alternatives[0].confidence);				
				});
			} else
				Materialize.toast('<span class="toast-warning">Please add some value to process.</span>', 4500);
		}
	</script>

	<!-- NLP SCRIPTS -->
	<script>
		$( "#submit_report_form" ).click(function() {
			value = document.getElementById('nlp_input').value;
			if (value != ''){
				$.ajax({
		            url: "https://language.googleapis.com/v1beta1/documents:analyzeEntities?key={{google_nlp_key}}",
		            type: 'POST',
		            contentType: "application/json; charset=utf-8",
		            data: JSON.stringify({
					  "document":{
					    "type":"PLAIN_TEXT",
					    "content": value
					  },
					  "encodingType":"UTF8"
					}) 
		        }).done(function(data) {
		        	console.log(data);
		        	var html = '<h5> The following entities have been detected (language: '+ data.language +'):</h5>';
		        	for (var i=0, j=data.entities.length; i<j; i++){
		        		html += '<p style="font-family:roboto-thin">"' + data.entities[i].name + '" interpreted as a ' + data.entities[i].type +' with a relevance among context of ' + data.entities[i].salience +'.</p>';
		        	}
		        	console.log(html);
		        	document.getElementById('nlp_response').innerHTML = html;

		        	if (data.language == "en"){
		        		$.ajax({
				            url: "https://language.googleapis.com/v1beta1/documents:analyzeSentiment?key={{google_nlp_key}}",
				            type: 'POST',
				            contentType: "application/json; charset=utf-8",
				            data: JSON.stringify({
							  "document":{
							    "type":"PLAIN_TEXT",
							    "content": value
							  }
							}) 
				        }).done(function(data) {
				        	console.log(data);
				        	document.getElementById('nlp_response').innerHTML += '<p style="font-family:roboto-black"> Sentiment detected has a magnitude of ' + data.documentSentiment.magnitude + ' with polarity of ' + data.documentSentiment.polarity + '.</p>';
				        });
				        
				        $.ajax({
				            url: "https://language.googleapis.com/v1beta1/documents:annotateText?key={{google_nlp_key}}",
				            type: 'POST',
				            contentType: "application/json; charset=utf-8",
				            data: JSON.stringify({
							  "document":{
							    "type":"PLAIN_TEXT",
							    "content": value
							  },
							  "features": {
							  	"extractSyntax": true,
								"extractEntities": true,
								"extractDocumentSentiment": true,
							  },
					  		  "encodingType":"UTF8"
							}) 
				        }).done(function(data) {
				        	console.log(data);
				        	document.getElementById('nlp_response').innerHTML += '<p style="font-family:roboto-black"> Total sentences: ' + data.sentences.length + '.</p>';
				        	document.getElementById('nlp_response').innerHTML += '<p style="font-family:roboto-black"> Total entities: ' + data.entities.length + '.</p>';
				        });
		        	}
		        });

		        
			}
		    else
    	        Materialize.toast('<span class="toast-warning">Please add some value to process.</span>',4500);
    	});
	</script>
{% endblock %}	
